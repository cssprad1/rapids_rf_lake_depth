{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest for Lake Depth\n",
    "\n",
    "Random Forest model implemented using RAPIDS AI's cuML and cuDF which run data manipulation, reading, training, etc on GPUs available instead of host CPUs. \n",
    "\n",
    "This random forest model takes in a csv which contains instances of tabulated spectral data from a specific raster stack. Each of the rows has 35 data-points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sytem and python modules\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "# Import RAPIDS specific modules\n",
    "\n",
    "import cudf as df\n",
    "import cuml\n",
    "from cuml import train_test_split\n",
    "from cuml.metrics.regression import r2_score as r2d2\n",
    "from cuml.ensemble import RandomForestRegressor as clRF\n",
    "\n",
    "# Import sklearn specific modules\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Import data-visualization modules\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare some globals variables and paths\n",
    "FEATURES_PATH = 'load_dataset/LakeDepth/pts_merged_final.csv'\n",
    "DEPTH = 'Depth_m'\n",
    "DATE = 'Date'\n",
    "FID = 'FID'\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load everything into GPU-based DF\n",
    "lakes_depth_df = df.read_csv(FEATURES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depth_m</th>\n",
       "      <th>b1_LC8_075</th>\n",
       "      <th>b2_LC8_075</th>\n",
       "      <th>b3_LC8_075</th>\n",
       "      <th>b4_LC8_075</th>\n",
       "      <th>b5_LC8_075</th>\n",
       "      <th>b6_LC8_075</th>\n",
       "      <th>b7_LC8_075</th>\n",
       "      <th>b8_LC8_075</th>\n",
       "      <th>b9_LC8_075</th>\n",
       "      <th>...</th>\n",
       "      <th>b26_LC8_07</th>\n",
       "      <th>b27_LC8_07</th>\n",
       "      <th>b28_LC8_07</th>\n",
       "      <th>b29_LC8_07</th>\n",
       "      <th>b30_LC8_07</th>\n",
       "      <th>b31_LC8_07</th>\n",
       "      <th>b32_LC8_07</th>\n",
       "      <th>b33_LC8_07</th>\n",
       "      <th>b34_LC8_07</th>\n",
       "      <th>b35_LC8_07</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.630000</td>\n",
       "      <td>164</td>\n",
       "      <td>271</td>\n",
       "      <td>199</td>\n",
       "      <td>42</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>605</td>\n",
       "      <td>824</td>\n",
       "      <td>3905</td>\n",
       "      <td>...</td>\n",
       "      <td>2625</td>\n",
       "      <td>165</td>\n",
       "      <td>100</td>\n",
       "      <td>136</td>\n",
       "      <td>643</td>\n",
       "      <td>98</td>\n",
       "      <td>59</td>\n",
       "      <td>80</td>\n",
       "      <td>381</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.672727</td>\n",
       "      <td>165</td>\n",
       "      <td>272</td>\n",
       "      <td>196</td>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>607</td>\n",
       "      <td>842</td>\n",
       "      <td>3750</td>\n",
       "      <td>...</td>\n",
       "      <td>2750</td>\n",
       "      <td>176</td>\n",
       "      <td>107</td>\n",
       "      <td>148</td>\n",
       "      <td>659</td>\n",
       "      <td>97</td>\n",
       "      <td>59</td>\n",
       "      <td>82</td>\n",
       "      <td>364</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.670588</td>\n",
       "      <td>154</td>\n",
       "      <td>260</td>\n",
       "      <td>193</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>592</td>\n",
       "      <td>798</td>\n",
       "      <td>3850</td>\n",
       "      <td>...</td>\n",
       "      <td>2105</td>\n",
       "      <td>208</td>\n",
       "      <td>123</td>\n",
       "      <td>166</td>\n",
       "      <td>800</td>\n",
       "      <td>123</td>\n",
       "      <td>73</td>\n",
       "      <td>98</td>\n",
       "      <td>475</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.822222</td>\n",
       "      <td>156</td>\n",
       "      <td>250</td>\n",
       "      <td>195</td>\n",
       "      <td>48</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "      <td>624</td>\n",
       "      <td>800</td>\n",
       "      <td>3250</td>\n",
       "      <td>...</td>\n",
       "      <td>1846</td>\n",
       "      <td>256</td>\n",
       "      <td>160</td>\n",
       "      <td>205</td>\n",
       "      <td>833</td>\n",
       "      <td>167</td>\n",
       "      <td>104</td>\n",
       "      <td>133</td>\n",
       "      <td>542</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.725000</td>\n",
       "      <td>117</td>\n",
       "      <td>164</td>\n",
       "      <td>78</td>\n",
       "      <td>38</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>713</td>\n",
       "      <td>1500</td>\n",
       "      <td>3079</td>\n",
       "      <td>...</td>\n",
       "      <td>2235</td>\n",
       "      <td>197</td>\n",
       "      <td>140</td>\n",
       "      <td>295</td>\n",
       "      <td>605</td>\n",
       "      <td>145</td>\n",
       "      <td>104</td>\n",
       "      <td>218</td>\n",
       "      <td>447</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Depth_m  b1_LC8_075  b2_LC8_075  b3_LC8_075  b4_LC8_075  b5_LC8_075  \\\n",
       "0  0.630000         164         271         199          42          27   \n",
       "1  0.672727         165         272         196          44          29   \n",
       "2  0.670588         154         260         193          40          32   \n",
       "3  0.822222         156         250         195          48          40   \n",
       "4  1.725000         117         164          78          38          23   \n",
       "\n",
       "   b6_LC8_075  b7_LC8_075  b8_LC8_075  b9_LC8_075  ...  b26_LC8_07  \\\n",
       "0          16         605         824        3905  ...        2625   \n",
       "1          16         607         842        3750  ...        2750   \n",
       "2          19         592         798        3850  ...        2105   \n",
       "3          26         624         800        3250  ...        1846   \n",
       "4          17         713        1500        3079  ...        2235   \n",
       "\n",
       "   b27_LC8_07  b28_LC8_07  b29_LC8_07  b30_LC8_07  b31_LC8_07  b32_LC8_07  \\\n",
       "0         165         100         136         643          98          59   \n",
       "1         176         107         148         659          97          59   \n",
       "2         208         123         166         800         123          73   \n",
       "3         256         160         205         833         167         104   \n",
       "4         197         140         295         605         145         104   \n",
       "\n",
       "   b33_LC8_07  b34_LC8_07  b35_LC8_07  \n",
       "0          80         381         593  \n",
       "1          82         364         552  \n",
       "2          98         475         594  \n",
       "3         133         542         650  \n",
       "4         218         447         739  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unnecessary values from DF\n",
    "lakes_depth_nd = lakes_depth_df.drop(['FID', 'Date'], axis = 1)\n",
    "lakes_depth_nd.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depth_m</th>\n",
       "      <th>b1_LC8_075</th>\n",
       "      <th>b2_LC8_075</th>\n",
       "      <th>b3_LC8_075</th>\n",
       "      <th>b4_LC8_075</th>\n",
       "      <th>b5_LC8_075</th>\n",
       "      <th>b6_LC8_075</th>\n",
       "      <th>b7_LC8_075</th>\n",
       "      <th>b8_LC8_075</th>\n",
       "      <th>b9_LC8_075</th>\n",
       "      <th>...</th>\n",
       "      <th>b26_LC8_07</th>\n",
       "      <th>b27_LC8_07</th>\n",
       "      <th>b28_LC8_07</th>\n",
       "      <th>b29_LC8_07</th>\n",
       "      <th>b30_LC8_07</th>\n",
       "      <th>b31_LC8_07</th>\n",
       "      <th>b32_LC8_07</th>\n",
       "      <th>b33_LC8_07</th>\n",
       "      <th>b34_LC8_07</th>\n",
       "      <th>b35_LC8_07</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.221400</td>\n",
       "      <td>424.288001</td>\n",
       "      <td>553.758079</td>\n",
       "      <td>427.147301</td>\n",
       "      <td>312.433188</td>\n",
       "      <td>175.490055</td>\n",
       "      <td>132.437373</td>\n",
       "      <td>558.585451</td>\n",
       "      <td>922.828753</td>\n",
       "      <td>1900.034603</td>\n",
       "      <td>...</td>\n",
       "      <td>4054.567977</td>\n",
       "      <td>473.428356</td>\n",
       "      <td>410.961686</td>\n",
       "      <td>544.808215</td>\n",
       "      <td>685.495103</td>\n",
       "      <td>332.496527</td>\n",
       "      <td>303.484877</td>\n",
       "      <td>394.607499</td>\n",
       "      <td>499.365880</td>\n",
       "      <td>768.926047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.872953</td>\n",
       "      <td>755.932158</td>\n",
       "      <td>731.549284</td>\n",
       "      <td>630.296958</td>\n",
       "      <td>479.544589</td>\n",
       "      <td>309.819959</td>\n",
       "      <td>244.022402</td>\n",
       "      <td>402.546098</td>\n",
       "      <td>2850.095960</td>\n",
       "      <td>3253.968664</td>\n",
       "      <td>...</td>\n",
       "      <td>6661.986500</td>\n",
       "      <td>2223.950009</td>\n",
       "      <td>539.947680</td>\n",
       "      <td>2837.452024</td>\n",
       "      <td>879.992656</td>\n",
       "      <td>1868.261448</td>\n",
       "      <td>395.559938</td>\n",
       "      <td>2580.861184</td>\n",
       "      <td>801.365571</td>\n",
       "      <td>455.468874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>-151.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>-39.000000</td>\n",
       "      <td>-38.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-3213.000000</td>\n",
       "      <td>-32768.000000</td>\n",
       "      <td>-32768.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-32768.000000</td>\n",
       "      <td>-32768.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-32768.000000</td>\n",
       "      <td>-32000.000000</td>\n",
       "      <td>-32768.000000</td>\n",
       "      <td>-22.000000</td>\n",
       "      <td>-32768.000000</td>\n",
       "      <td>-31000.000000</td>\n",
       "      <td>-9667.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.405170</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>607.000000</td>\n",
       "      <td>753.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1413.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>391.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>651.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.870750</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>621.000000</td>\n",
       "      <td>933.000000</td>\n",
       "      <td>1626.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2126.000000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>271.000000</td>\n",
       "      <td>661.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>453.000000</td>\n",
       "      <td>734.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.348770</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>441.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>789.000000</td>\n",
       "      <td>1241.000000</td>\n",
       "      <td>3294.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3500.000000</td>\n",
       "      <td>643.000000</td>\n",
       "      <td>588.000000</td>\n",
       "      <td>843.000000</td>\n",
       "      <td>895.000000</td>\n",
       "      <td>458.000000</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>620.000000</td>\n",
       "      <td>679.000000</td>\n",
       "      <td>828.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.037500</td>\n",
       "      <td>5277.000000</td>\n",
       "      <td>5442.000000</td>\n",
       "      <td>4984.000000</td>\n",
       "      <td>5370.000000</td>\n",
       "      <td>2879.000000</td>\n",
       "      <td>2568.000000</td>\n",
       "      <td>4171.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>4128.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Depth_m    b1_LC8_075    b2_LC8_075    b3_LC8_075    b4_LC8_075  \\\n",
       "count  23177.000000  23177.000000  23177.000000  23177.000000  23177.000000   \n",
       "mean       2.221400    424.288001    553.758079    427.147301    312.433188   \n",
       "std        1.872953    755.932158    731.549284    630.296958    479.544589   \n",
       "min        0.250000   -151.000000     47.000000    -39.000000    -38.000000   \n",
       "25%        1.405170    128.000000    235.000000    116.000000     52.000000   \n",
       "50%        1.870750    189.000000    324.000000    224.000000    118.000000   \n",
       "75%        2.348770    262.000000    441.000000    379.000000    337.000000   \n",
       "max       21.037500   5277.000000   5442.000000   4984.000000   5370.000000   \n",
       "\n",
       "         b5_LC8_075    b6_LC8_075    b7_LC8_075    b8_LC8_075    b9_LC8_075  \\\n",
       "count  23177.000000  23177.000000  23177.000000  23177.000000  23177.000000   \n",
       "mean     175.490055    132.437373    558.585451    922.828753   1900.034603   \n",
       "std      309.819959    244.022402    402.546098   2850.095960   3253.968664   \n",
       "min       -3.000000     -9.000000  -3213.000000 -32768.000000 -32768.000000   \n",
       "25%       29.000000     20.000000    429.000000    607.000000    753.000000   \n",
       "50%       51.000000     37.000000    621.000000    933.000000   1626.000000   \n",
       "75%      164.000000    120.000000    789.000000   1241.000000   3294.000000   \n",
       "max     2879.000000   2568.000000   4171.000000  32767.000000  32767.000000   \n",
       "\n",
       "       ...    b26_LC8_07    b27_LC8_07    b28_LC8_07    b29_LC8_07  \\\n",
       "count  ...  23177.000000  23177.000000  23177.000000  23177.000000   \n",
       "mean   ...   4054.567977    473.428356    410.961686    544.808215   \n",
       "std    ...   6661.986500   2223.950009    539.947680   2837.452024   \n",
       "min    ... -32768.000000 -32768.000000     -8.000000 -32768.000000   \n",
       "25%    ...   1413.000000    126.000000     88.000000    130.000000   \n",
       "50%    ...   2126.000000    246.000000    155.000000    271.000000   \n",
       "75%    ...   3500.000000    643.000000    588.000000    843.000000   \n",
       "max    ...  32767.000000  32767.000000   4128.000000  32767.000000   \n",
       "\n",
       "         b30_LC8_07    b31_LC8_07    b32_LC8_07    b33_LC8_07    b34_LC8_07  \\\n",
       "count  23177.000000  23177.000000  23177.000000  23177.000000  23177.000000   \n",
       "mean     685.495103    332.496527    303.484877    394.607499    499.365880   \n",
       "std      879.992656   1868.261448    395.559938   2580.861184    801.365571   \n",
       "min   -32000.000000 -32768.000000    -22.000000 -32768.000000 -31000.000000   \n",
       "25%      391.000000     87.000000     63.000000     94.000000    265.000000   \n",
       "50%      661.000000    173.000000    105.000000    189.000000    453.000000   \n",
       "75%      895.000000    458.000000    460.000000    620.000000    679.000000   \n",
       "max    32767.000000  32767.000000   2771.000000  32767.000000  32767.000000   \n",
       "\n",
       "         b35_LC8_07  \n",
       "count  23177.000000  \n",
       "mean     768.926047  \n",
       "std      455.468874  \n",
       "min    -9667.000000  \n",
       "25%      651.000000  \n",
       "50%      734.000000  \n",
       "75%      828.000000  \n",
       "max    32767.000000  \n",
       "\n",
       "[8 rows x 36 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect data for any anomolies or anything else odd-looking\n",
    "lakes_depth_nd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.630000\n",
       "1    0.672727\n",
       "2    0.670588\n",
       "3    0.822222\n",
       "4    1.725000\n",
       "Name: Depth_m, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make our acutal_predictions i.e. labels and our covariates dataframes\n",
    "labels = lakes_depth_nd['Depth_m']\n",
    "covariates = lakes_depth_nd.drop(['Depth_m'], axis=1)\n",
    "\n",
    "# Check to ensure everything looks good\n",
    "labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1_LC8_075</th>\n",
       "      <th>b2_LC8_075</th>\n",
       "      <th>b3_LC8_075</th>\n",
       "      <th>b4_LC8_075</th>\n",
       "      <th>b5_LC8_075</th>\n",
       "      <th>b6_LC8_075</th>\n",
       "      <th>b7_LC8_075</th>\n",
       "      <th>b8_LC8_075</th>\n",
       "      <th>b9_LC8_075</th>\n",
       "      <th>b10_LC8_07</th>\n",
       "      <th>...</th>\n",
       "      <th>b26_LC8_07</th>\n",
       "      <th>b27_LC8_07</th>\n",
       "      <th>b28_LC8_07</th>\n",
       "      <th>b29_LC8_07</th>\n",
       "      <th>b30_LC8_07</th>\n",
       "      <th>b31_LC8_07</th>\n",
       "      <th>b32_LC8_07</th>\n",
       "      <th>b33_LC8_07</th>\n",
       "      <th>b34_LC8_07</th>\n",
       "      <th>b35_LC8_07</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>164</td>\n",
       "      <td>271</td>\n",
       "      <td>199</td>\n",
       "      <td>42</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>605</td>\n",
       "      <td>824</td>\n",
       "      <td>3905</td>\n",
       "      <td>6074</td>\n",
       "      <td>...</td>\n",
       "      <td>2625</td>\n",
       "      <td>165</td>\n",
       "      <td>100</td>\n",
       "      <td>136</td>\n",
       "      <td>643</td>\n",
       "      <td>98</td>\n",
       "      <td>59</td>\n",
       "      <td>80</td>\n",
       "      <td>381</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165</td>\n",
       "      <td>272</td>\n",
       "      <td>196</td>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>607</td>\n",
       "      <td>842</td>\n",
       "      <td>3750</td>\n",
       "      <td>5690</td>\n",
       "      <td>...</td>\n",
       "      <td>2750</td>\n",
       "      <td>176</td>\n",
       "      <td>107</td>\n",
       "      <td>148</td>\n",
       "      <td>659</td>\n",
       "      <td>97</td>\n",
       "      <td>59</td>\n",
       "      <td>82</td>\n",
       "      <td>364</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>154</td>\n",
       "      <td>260</td>\n",
       "      <td>193</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>592</td>\n",
       "      <td>798</td>\n",
       "      <td>3850</td>\n",
       "      <td>4813</td>\n",
       "      <td>...</td>\n",
       "      <td>2105</td>\n",
       "      <td>208</td>\n",
       "      <td>123</td>\n",
       "      <td>166</td>\n",
       "      <td>800</td>\n",
       "      <td>123</td>\n",
       "      <td>73</td>\n",
       "      <td>98</td>\n",
       "      <td>475</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156</td>\n",
       "      <td>250</td>\n",
       "      <td>195</td>\n",
       "      <td>48</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "      <td>624</td>\n",
       "      <td>800</td>\n",
       "      <td>3250</td>\n",
       "      <td>3900</td>\n",
       "      <td>...</td>\n",
       "      <td>1846</td>\n",
       "      <td>256</td>\n",
       "      <td>160</td>\n",
       "      <td>205</td>\n",
       "      <td>833</td>\n",
       "      <td>167</td>\n",
       "      <td>104</td>\n",
       "      <td>133</td>\n",
       "      <td>542</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117</td>\n",
       "      <td>164</td>\n",
       "      <td>78</td>\n",
       "      <td>38</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>713</td>\n",
       "      <td>1500</td>\n",
       "      <td>3079</td>\n",
       "      <td>5087</td>\n",
       "      <td>...</td>\n",
       "      <td>2235</td>\n",
       "      <td>197</td>\n",
       "      <td>140</td>\n",
       "      <td>295</td>\n",
       "      <td>605</td>\n",
       "      <td>145</td>\n",
       "      <td>104</td>\n",
       "      <td>218</td>\n",
       "      <td>447</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   b1_LC8_075  b2_LC8_075  b3_LC8_075  b4_LC8_075  b5_LC8_075  b6_LC8_075  \\\n",
       "0         164         271         199          42          27          16   \n",
       "1         165         272         196          44          29          16   \n",
       "2         154         260         193          40          32          19   \n",
       "3         156         250         195          48          40          26   \n",
       "4         117         164          78          38          23          17   \n",
       "\n",
       "   b7_LC8_075  b8_LC8_075  b9_LC8_075  b10_LC8_07  ...  b26_LC8_07  \\\n",
       "0         605         824        3905        6074  ...        2625   \n",
       "1         607         842        3750        5690  ...        2750   \n",
       "2         592         798        3850        4813  ...        2105   \n",
       "3         624         800        3250        3900  ...        1846   \n",
       "4         713        1500        3079        5087  ...        2235   \n",
       "\n",
       "   b27_LC8_07  b28_LC8_07  b29_LC8_07  b30_LC8_07  b31_LC8_07  b32_LC8_07  \\\n",
       "0         165         100         136         643          98          59   \n",
       "1         176         107         148         659          97          59   \n",
       "2         208         123         166         800         123          73   \n",
       "3         256         160         205         833         167         104   \n",
       "4         197         140         295         605         145         104   \n",
       "\n",
       "   b33_LC8_07  b34_LC8_07  b35_LC8_07  \n",
       "0          80         381         593  \n",
       "1          82         364         552  \n",
       "2          98         475         594  \n",
       "3         133         542         650  \n",
       "4         218         447         739  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariates.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we change all our covariate and label data to float32\n",
    "\n",
    "labels = labels.astype(cp.float32)\n",
    "covariates = covariates.astype(cp.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data to prep for model training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_train, cv_test, labels_train, labels_test = train_test_split(covariates, labels,\n",
    "                                                               test_size=TEST_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (18542, 35)\n",
      "Testing features shape: (4635, 35)\n",
      "Training labels shape: (18542,)\n",
      "Testing labels shape: (4635,)\n"
     ]
    }
   ],
   "source": [
    "# Ensure we have the right size and shapes on our split data\n",
    "print('Training features shape:', cv_train.shape)\n",
    "print('Testing features shape:', cv_test.shape)\n",
    "print('Training labels shape:', labels_train.shape)\n",
    "print('Testing labels shape:', labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare some global variables for training phase\n",
    "\n",
    "# Hyper-paramters\n",
    "N_ESTIMATORS = 1000\n",
    "SPLIT_ALGO = 1\n",
    "SPLIT_CRITERION = 2\n",
    "BOOTSTRAP = True\n",
    "BOOTSTRAP_FEATURES = False\n",
    "ROWS_SAMPLE = 1.0\n",
    "MAX_DEPTH = 16\n",
    "MAX_LEAVES = -1\n",
    "MAX_FEATURES = 'auto'\n",
    "N_BINS = 8\n",
    "MIN_ROWS_PER_NODE = 2\n",
    "MIN_IMPURITY_DECREASE = 0.0\n",
    "ACCURACY_METRIC = 'r2' # 'median_aw' # 'mean_ae' # 'mse' #\n",
    "QUANTILEPT = False\n",
    "SEED = 42\n",
    "VERBOSE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_ae\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cssprad1/.conda/envs/rapids-0.16/lib/python3.7/site-packages/ipykernel_launcher.py:16: DeprecationWarning: Parameter 'seed' is deprecated and will be removed in 0.17. Please use 'random_state' instead. Setting 'random_state' as the curent 'seed' value\n",
      "  app.launch_new_instance()\n",
      "/home/cssprad1/.conda/envs/rapids-0.16/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams==1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "depth_rf_model_0 = clRF(n_estimators = N_ESTIMATORS, \n",
    "                        split_algo = SPLIT_ALGO, \n",
    "                        split_criterion = SPLIT_CRITERION, \n",
    "                        bootstrap = BOOTSTRAP,\n",
    "                        bootstrap_features = BOOTSTRAP_FEATURES, \n",
    "                        rows_sample = ROWS_SAMPLE,\n",
    "                        max_depth = MAX_DEPTH, \n",
    "                        max_leaves = MAX_LEAVES, \n",
    "                        max_features = MAX_FEATURES,\n",
    "                        n_bins = N_BINS,\n",
    "                        min_rows_per_node = MIN_ROWS_PER_NODE,\n",
    "                        min_impurity_decrease = MIN_IMPURITY_DECREASE,\n",
    "                        accuracy_metric = ACCURACY_METRIC,\n",
    "                        quantile_per_tree = QUANTILEPT,\n",
    "                        seed = SEED,\n",
    "                        verbose = VERBOSE)\n",
    "\n",
    "print(depth_rf_model_0.accuracy_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.2 s, sys: 7.46 s, total: 20.6 s\n",
      "Wall time: 3.76 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(split_criterion=2, accuracy_metric='mean_ae', handle=<cuml.raft.common.handle.Handle object at 0x7f82943132b0>, verbose=4, output_type='cudf')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Train the model (!!)\n",
    "\n",
    "depth_rf_model_0.fit(cv_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction and analyzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores --\n",
      "MAE score: 0.4655255486214174\n"
     ]
    }
   ],
   "source": [
    "# Let's get some predictions\n",
    "score_model_0 = depth_rf_model_0.score(cv_test, labels_test)\n",
    "#model_0_predictions = depth_rf_model_0.predict(cv_test)\n",
    "#errors = abs(model_0_predictions - labels_test)\n",
    "print(\"Scores --\")\n",
    "print(\"MAE score:\", score_model_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(labels_test.to_array(), model_0_predictions.to_array())\n",
    "plt.xlabel(\"Actual Depth: $Y_i$\")\n",
    "plt.ylabel(\"Predicted Dpeth: $\\hat{Y}_i$\")\n",
    "plt.title(\"Lake Depth vs Predicted Lake Depth: $Y_i$ vs $\\hat{Y}_i$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:  1.31369 Predicted 1.391508\n",
      "Actual:  1.01975 Predicted 1.2669924\n",
      "Actual:  1.77957 Predicted 2.099687\n",
      "Actual:  1.949 Predicted 1.8762205\n",
      "Actual:  2.994 Predicted 2.5476096\n",
      "Actual:  2.79733 Predicted 2.6412184\n",
      "Actual:  1.8745 Predicted 1.9585304\n",
      "Actual:  1.51517 Predicted 1.6615586\n",
      "Actual:  2.10836 Predicted 1.6700078\n",
      "Actual:  2.45464 Predicted 2.7825665\n",
      "Actual:  2.12477 Predicted 1.8160639\n",
      "Actual:  2.05803 Predicted 2.3401775\n",
      "Actual:  1.73906 Predicted 2.0880141\n",
      "Actual:  1.90694 Predicted 2.099918\n",
      "Actual:  0.919917 Predicted 1.4699366\n",
      "Actual:  1.53521 Predicted 1.4039077\n",
      "Actual:  2.9724 Predicted 2.3091762\n",
      "Actual:  1.36235 Predicted 1.3984163\n",
      "Actual:  3.7716 Predicted 3.0252059\n",
      "Actual:  1.325 Predicted 2.1284554\n"
     ]
    }
   ],
   "source": [
    "# Lets look at a random sample of datapoints to see the actual vs predicted depths\n",
    "for i in range(20):\n",
    "    random_data_point = random.randint(4635)\n",
    "    print('Actual: {:20} Predicted: {}'.format(labels_test.to_array()[random_data_point],\n",
    "                                               model_0_predictions.to_array()[random_data_point]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized Search - Cross Validation\n",
    "(We want to find the optimal hyper-parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomized search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance\n",
    "\n",
    "Find the permutation importance using sklearn's implementation (works with cuML models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables: b15_LC8_07           Importance: 0.02785\n",
      "Variables: b28_LC8_07           Importance: 0.03696\n",
      "Variables: b16_LC8_07           Importance: 0.03771\n",
      "Variables: b32_LC8_07           Importance: 0.03803\n",
      "Variables: b21_LC8_07           Importance: 0.05529\n",
      "Variables: b14_LC8_07           Importance: 0.05677\n",
      "Variables: b9_LC8_075           Importance: 0.05875\n",
      "Variables: b22_LC8_07           Importance: 0.06029\n",
      "Variables: b11_LC8_07           Importance: 0.0606\n",
      "Variables: b31_LC8_07           Importance: 0.06127\n",
      "Variables: b5_LC8_075           Importance: 0.06227\n",
      "Variables: b6_LC8_075           Importance: 0.06358\n",
      "Variables: b4_LC8_075           Importance: 0.06743\n",
      "Variables: b10_LC8_07           Importance: 0.06804\n",
      "Variables: b27_LC8_07           Importance: 0.07037\n",
      "Variables: b35_LC8_07           Importance: 0.07215\n",
      "Variables: b33_LC8_07           Importance: 0.07731\n",
      "Variables: b20_LC8_07           Importance: 0.08338\n",
      "Variables: b1_LC8_075           Importance: 0.08636\n",
      "Variables: b29_LC8_07           Importance: 0.08942\n",
      "Variables: b2_LC8_075           Importance: 0.08994\n",
      "Variables: b3_LC8_075           Importance: 0.09048\n",
      "Variables: b34_LC8_07           Importance: 0.09582\n",
      "Variables: b23_LC8_07           Importance: 0.09632\n",
      "Variables: b19_LC8_07           Importance: 0.09737\n",
      "Variables: b30_LC8_07           Importance: 0.09923\n",
      "Variables: b26_LC8_07           Importance: 0.10346\n",
      "Variables: b12_LC8_07           Importance: 0.12466\n",
      "Variables: b13_LC8_07           Importance: 0.12481\n",
      "Variables: b25_LC8_07           Importance: 0.12512\n",
      "Variables: b7_LC8_075           Importance: 0.12683\n",
      "Variables: b18_LC8_07           Importance: 0.13079\n",
      "Variables: b24_LC8_07           Importance: 0.1744\n",
      "Variables: b17_LC8_07           Importance: 0.18422\n",
      "Variables: b8_LC8_075           Importance: 0.2043\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "perm_imp = permutation_importance(depth_rf_model_0, cv_test, labels_test)\n",
    "spectral_bands_list = list(covariates.columns)\n",
    "importances = perm_imp.importances_mean\n",
    "feature_importances = [(feature, -1*(round(importance, 5))) for\n",
    "                      feature, importance in zip(spectral_bands_list, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Variables: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-rapids-0.16]",
   "language": "python",
   "name": "conda-env-.conda-rapids-0.16-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
