{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random as rand\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    import pydot\n",
    "except ModuleNotFoundError:\n",
    "    os.system('conda install -c conda-forge pydot -y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data from data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FID</th>\n",
       "      <th>Depth_m</th>\n",
       "      <th>Date</th>\n",
       "      <th>b1_LC8_075</th>\n",
       "      <th>b2_LC8_075</th>\n",
       "      <th>b3_LC8_075</th>\n",
       "      <th>b4_LC8_075</th>\n",
       "      <th>b5_LC8_075</th>\n",
       "      <th>b6_LC8_075</th>\n",
       "      <th>b7_LC8_075</th>\n",
       "      <th>...</th>\n",
       "      <th>b26_LC8_07</th>\n",
       "      <th>b27_LC8_07</th>\n",
       "      <th>b28_LC8_07</th>\n",
       "      <th>b29_LC8_07</th>\n",
       "      <th>b30_LC8_07</th>\n",
       "      <th>b31_LC8_07</th>\n",
       "      <th>b32_LC8_07</th>\n",
       "      <th>b33_LC8_07</th>\n",
       "      <th>b34_LC8_07</th>\n",
       "      <th>b35_LC8_07</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>7/22/2017 0:00</td>\n",
       "      <td>164</td>\n",
       "      <td>271</td>\n",
       "      <td>199</td>\n",
       "      <td>42</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>605</td>\n",
       "      <td>...</td>\n",
       "      <td>2625</td>\n",
       "      <td>165</td>\n",
       "      <td>100</td>\n",
       "      <td>136</td>\n",
       "      <td>643</td>\n",
       "      <td>98</td>\n",
       "      <td>59</td>\n",
       "      <td>80</td>\n",
       "      <td>381</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>7/22/2017 0:00</td>\n",
       "      <td>165</td>\n",
       "      <td>272</td>\n",
       "      <td>196</td>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>607</td>\n",
       "      <td>...</td>\n",
       "      <td>2750</td>\n",
       "      <td>176</td>\n",
       "      <td>107</td>\n",
       "      <td>148</td>\n",
       "      <td>659</td>\n",
       "      <td>97</td>\n",
       "      <td>59</td>\n",
       "      <td>82</td>\n",
       "      <td>364</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>7/22/2017 0:00</td>\n",
       "      <td>154</td>\n",
       "      <td>260</td>\n",
       "      <td>193</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>592</td>\n",
       "      <td>...</td>\n",
       "      <td>2105</td>\n",
       "      <td>208</td>\n",
       "      <td>123</td>\n",
       "      <td>166</td>\n",
       "      <td>800</td>\n",
       "      <td>123</td>\n",
       "      <td>73</td>\n",
       "      <td>98</td>\n",
       "      <td>475</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>7/22/2017 0:00</td>\n",
       "      <td>156</td>\n",
       "      <td>250</td>\n",
       "      <td>195</td>\n",
       "      <td>48</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "      <td>624</td>\n",
       "      <td>...</td>\n",
       "      <td>1846</td>\n",
       "      <td>256</td>\n",
       "      <td>160</td>\n",
       "      <td>205</td>\n",
       "      <td>833</td>\n",
       "      <td>167</td>\n",
       "      <td>104</td>\n",
       "      <td>133</td>\n",
       "      <td>542</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.725000</td>\n",
       "      <td>7/22/2017 0:00</td>\n",
       "      <td>117</td>\n",
       "      <td>164</td>\n",
       "      <td>78</td>\n",
       "      <td>38</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>713</td>\n",
       "      <td>...</td>\n",
       "      <td>2235</td>\n",
       "      <td>197</td>\n",
       "      <td>140</td>\n",
       "      <td>295</td>\n",
       "      <td>605</td>\n",
       "      <td>145</td>\n",
       "      <td>104</td>\n",
       "      <td>218</td>\n",
       "      <td>447</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FID   Depth_m            Date  b1_LC8_075  b2_LC8_075  b3_LC8_075  \\\n",
       "0    0  0.630000  7/22/2017 0:00         164         271         199   \n",
       "1    1  0.672727  7/22/2017 0:00         165         272         196   \n",
       "2    2  0.670588  7/22/2017 0:00         154         260         193   \n",
       "3    3  0.822222  7/22/2017 0:00         156         250         195   \n",
       "4    4  1.725000  7/22/2017 0:00         117         164          78   \n",
       "\n",
       "   b4_LC8_075  b5_LC8_075  b6_LC8_075  b7_LC8_075  ...  b26_LC8_07  \\\n",
       "0          42          27          16         605  ...        2625   \n",
       "1          44          29          16         607  ...        2750   \n",
       "2          40          32          19         592  ...        2105   \n",
       "3          48          40          26         624  ...        1846   \n",
       "4          38          23          17         713  ...        2235   \n",
       "\n",
       "   b27_LC8_07  b28_LC8_07  b29_LC8_07  b30_LC8_07  b31_LC8_07  b32_LC8_07  \\\n",
       "0         165         100         136         643          98          59   \n",
       "1         176         107         148         659          97          59   \n",
       "2         208         123         166         800         123          73   \n",
       "3         256         160         205         833         167         104   \n",
       "4         197         140         295         605         145         104   \n",
       "\n",
       "   b33_LC8_07  b34_LC8_07  b35_LC8_07  \n",
       "0          80         381         593  \n",
       "1          82         364         552  \n",
       "2          98         475         594  \n",
       "3         133         542         650  \n",
       "4         218         447         739  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_lake_depth_data = pd.read_csv('load_dataset/LakeDepth/pts_merged_final.csv')\n",
    "overall_lake_depth_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the FID and Data from the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depth_m</th>\n",
       "      <th>b1_LC8_075</th>\n",
       "      <th>b2_LC8_075</th>\n",
       "      <th>b3_LC8_075</th>\n",
       "      <th>b4_LC8_075</th>\n",
       "      <th>b5_LC8_075</th>\n",
       "      <th>b6_LC8_075</th>\n",
       "      <th>b7_LC8_075</th>\n",
       "      <th>b8_LC8_075</th>\n",
       "      <th>b9_LC8_075</th>\n",
       "      <th>...</th>\n",
       "      <th>b26_LC8_07</th>\n",
       "      <th>b27_LC8_07</th>\n",
       "      <th>b28_LC8_07</th>\n",
       "      <th>b29_LC8_07</th>\n",
       "      <th>b30_LC8_07</th>\n",
       "      <th>b31_LC8_07</th>\n",
       "      <th>b32_LC8_07</th>\n",
       "      <th>b33_LC8_07</th>\n",
       "      <th>b34_LC8_07</th>\n",
       "      <th>b35_LC8_07</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.630000</td>\n",
       "      <td>164</td>\n",
       "      <td>271</td>\n",
       "      <td>199</td>\n",
       "      <td>42</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>605</td>\n",
       "      <td>824</td>\n",
       "      <td>3905</td>\n",
       "      <td>...</td>\n",
       "      <td>2625</td>\n",
       "      <td>165</td>\n",
       "      <td>100</td>\n",
       "      <td>136</td>\n",
       "      <td>643</td>\n",
       "      <td>98</td>\n",
       "      <td>59</td>\n",
       "      <td>80</td>\n",
       "      <td>381</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.672727</td>\n",
       "      <td>165</td>\n",
       "      <td>272</td>\n",
       "      <td>196</td>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>607</td>\n",
       "      <td>842</td>\n",
       "      <td>3750</td>\n",
       "      <td>...</td>\n",
       "      <td>2750</td>\n",
       "      <td>176</td>\n",
       "      <td>107</td>\n",
       "      <td>148</td>\n",
       "      <td>659</td>\n",
       "      <td>97</td>\n",
       "      <td>59</td>\n",
       "      <td>82</td>\n",
       "      <td>364</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.670588</td>\n",
       "      <td>154</td>\n",
       "      <td>260</td>\n",
       "      <td>193</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>592</td>\n",
       "      <td>798</td>\n",
       "      <td>3850</td>\n",
       "      <td>...</td>\n",
       "      <td>2105</td>\n",
       "      <td>208</td>\n",
       "      <td>123</td>\n",
       "      <td>166</td>\n",
       "      <td>800</td>\n",
       "      <td>123</td>\n",
       "      <td>73</td>\n",
       "      <td>98</td>\n",
       "      <td>475</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.822222</td>\n",
       "      <td>156</td>\n",
       "      <td>250</td>\n",
       "      <td>195</td>\n",
       "      <td>48</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "      <td>624</td>\n",
       "      <td>800</td>\n",
       "      <td>3250</td>\n",
       "      <td>...</td>\n",
       "      <td>1846</td>\n",
       "      <td>256</td>\n",
       "      <td>160</td>\n",
       "      <td>205</td>\n",
       "      <td>833</td>\n",
       "      <td>167</td>\n",
       "      <td>104</td>\n",
       "      <td>133</td>\n",
       "      <td>542</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.725000</td>\n",
       "      <td>117</td>\n",
       "      <td>164</td>\n",
       "      <td>78</td>\n",
       "      <td>38</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>713</td>\n",
       "      <td>1500</td>\n",
       "      <td>3079</td>\n",
       "      <td>...</td>\n",
       "      <td>2235</td>\n",
       "      <td>197</td>\n",
       "      <td>140</td>\n",
       "      <td>295</td>\n",
       "      <td>605</td>\n",
       "      <td>145</td>\n",
       "      <td>104</td>\n",
       "      <td>218</td>\n",
       "      <td>447</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Depth_m  b1_LC8_075  b2_LC8_075  b3_LC8_075  b4_LC8_075  b5_LC8_075  \\\n",
       "0  0.630000         164         271         199          42          27   \n",
       "1  0.672727         165         272         196          44          29   \n",
       "2  0.670588         154         260         193          40          32   \n",
       "3  0.822222         156         250         195          48          40   \n",
       "4  1.725000         117         164          78          38          23   \n",
       "\n",
       "   b6_LC8_075  b7_LC8_075  b8_LC8_075  b9_LC8_075  ...  b26_LC8_07  \\\n",
       "0          16         605         824        3905  ...        2625   \n",
       "1          16         607         842        3750  ...        2750   \n",
       "2          19         592         798        3850  ...        2105   \n",
       "3          26         624         800        3250  ...        1846   \n",
       "4          17         713        1500        3079  ...        2235   \n",
       "\n",
       "   b27_LC8_07  b28_LC8_07  b29_LC8_07  b30_LC8_07  b31_LC8_07  b32_LC8_07  \\\n",
       "0         165         100         136         643          98          59   \n",
       "1         176         107         148         659          97          59   \n",
       "2         208         123         166         800         123          73   \n",
       "3         256         160         205         833         167         104   \n",
       "4         197         140         295         605         145         104   \n",
       "\n",
       "   b33_LC8_07  b34_LC8_07  b35_LC8_07  \n",
       "0          80         381         593  \n",
       "1          82         364         552  \n",
       "2          98         475         594  \n",
       "3         133         542         650  \n",
       "4         218         447         739  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_lake_depth_nd = overall_lake_depth_data.drop(['FID', 'Date'], axis=1)\n",
    "overall_lake_depth_nd.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe statistics to report anamolous data\n",
    "Look for anything weird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depth_m</th>\n",
       "      <th>b1_LC8_075</th>\n",
       "      <th>b2_LC8_075</th>\n",
       "      <th>b3_LC8_075</th>\n",
       "      <th>b4_LC8_075</th>\n",
       "      <th>b5_LC8_075</th>\n",
       "      <th>b6_LC8_075</th>\n",
       "      <th>b7_LC8_075</th>\n",
       "      <th>b8_LC8_075</th>\n",
       "      <th>b9_LC8_075</th>\n",
       "      <th>...</th>\n",
       "      <th>b26_LC8_07</th>\n",
       "      <th>b27_LC8_07</th>\n",
       "      <th>b28_LC8_07</th>\n",
       "      <th>b29_LC8_07</th>\n",
       "      <th>b30_LC8_07</th>\n",
       "      <th>b31_LC8_07</th>\n",
       "      <th>b32_LC8_07</th>\n",
       "      <th>b33_LC8_07</th>\n",
       "      <th>b34_LC8_07</th>\n",
       "      <th>b35_LC8_07</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.221400</td>\n",
       "      <td>424.288001</td>\n",
       "      <td>553.758079</td>\n",
       "      <td>427.147301</td>\n",
       "      <td>312.433188</td>\n",
       "      <td>175.490055</td>\n",
       "      <td>132.437373</td>\n",
       "      <td>558.585451</td>\n",
       "      <td>922.828753</td>\n",
       "      <td>1900.034603</td>\n",
       "      <td>...</td>\n",
       "      <td>4054.567977</td>\n",
       "      <td>473.428356</td>\n",
       "      <td>410.961686</td>\n",
       "      <td>544.808215</td>\n",
       "      <td>685.495103</td>\n",
       "      <td>332.496527</td>\n",
       "      <td>303.484877</td>\n",
       "      <td>394.607499</td>\n",
       "      <td>499.365880</td>\n",
       "      <td>768.926047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.872953</td>\n",
       "      <td>755.932158</td>\n",
       "      <td>731.549284</td>\n",
       "      <td>630.296958</td>\n",
       "      <td>479.544589</td>\n",
       "      <td>309.819959</td>\n",
       "      <td>244.022402</td>\n",
       "      <td>402.546098</td>\n",
       "      <td>2850.095960</td>\n",
       "      <td>3253.968664</td>\n",
       "      <td>...</td>\n",
       "      <td>6661.986500</td>\n",
       "      <td>2223.950009</td>\n",
       "      <td>539.947680</td>\n",
       "      <td>2837.452024</td>\n",
       "      <td>879.992656</td>\n",
       "      <td>1868.261448</td>\n",
       "      <td>395.559938</td>\n",
       "      <td>2580.861184</td>\n",
       "      <td>801.365571</td>\n",
       "      <td>455.468874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>-151.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>-39.000000</td>\n",
       "      <td>-38.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-3213.000000</td>\n",
       "      <td>-32768.000000</td>\n",
       "      <td>-32768.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-32768.000000</td>\n",
       "      <td>-32768.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-32768.000000</td>\n",
       "      <td>-32000.000000</td>\n",
       "      <td>-32768.000000</td>\n",
       "      <td>-22.000000</td>\n",
       "      <td>-32768.000000</td>\n",
       "      <td>-31000.000000</td>\n",
       "      <td>-9667.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.405170</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>607.000000</td>\n",
       "      <td>753.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1413.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>391.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>651.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.870750</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>621.000000</td>\n",
       "      <td>933.000000</td>\n",
       "      <td>1626.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2126.000000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>271.000000</td>\n",
       "      <td>661.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>453.000000</td>\n",
       "      <td>734.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.348770</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>441.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>789.000000</td>\n",
       "      <td>1241.000000</td>\n",
       "      <td>3294.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3500.000000</td>\n",
       "      <td>643.000000</td>\n",
       "      <td>588.000000</td>\n",
       "      <td>843.000000</td>\n",
       "      <td>895.000000</td>\n",
       "      <td>458.000000</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>620.000000</td>\n",
       "      <td>679.000000</td>\n",
       "      <td>828.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.037500</td>\n",
       "      <td>5277.000000</td>\n",
       "      <td>5442.000000</td>\n",
       "      <td>4984.000000</td>\n",
       "      <td>5370.000000</td>\n",
       "      <td>2879.000000</td>\n",
       "      <td>2568.000000</td>\n",
       "      <td>4171.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>4128.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Depth_m    b1_LC8_075    b2_LC8_075    b3_LC8_075    b4_LC8_075  \\\n",
       "count  23177.000000  23177.000000  23177.000000  23177.000000  23177.000000   \n",
       "mean       2.221400    424.288001    553.758079    427.147301    312.433188   \n",
       "std        1.872953    755.932158    731.549284    630.296958    479.544589   \n",
       "min        0.250000   -151.000000     47.000000    -39.000000    -38.000000   \n",
       "25%        1.405170    128.000000    235.000000    116.000000     52.000000   \n",
       "50%        1.870750    189.000000    324.000000    224.000000    118.000000   \n",
       "75%        2.348770    262.000000    441.000000    379.000000    337.000000   \n",
       "max       21.037500   5277.000000   5442.000000   4984.000000   5370.000000   \n",
       "\n",
       "         b5_LC8_075    b6_LC8_075    b7_LC8_075    b8_LC8_075    b9_LC8_075  \\\n",
       "count  23177.000000  23177.000000  23177.000000  23177.000000  23177.000000   \n",
       "mean     175.490055    132.437373    558.585451    922.828753   1900.034603   \n",
       "std      309.819959    244.022402    402.546098   2850.095960   3253.968664   \n",
       "min       -3.000000     -9.000000  -3213.000000 -32768.000000 -32768.000000   \n",
       "25%       29.000000     20.000000    429.000000    607.000000    753.000000   \n",
       "50%       51.000000     37.000000    621.000000    933.000000   1626.000000   \n",
       "75%      164.000000    120.000000    789.000000   1241.000000   3294.000000   \n",
       "max     2879.000000   2568.000000   4171.000000  32767.000000  32767.000000   \n",
       "\n",
       "       ...    b26_LC8_07    b27_LC8_07    b28_LC8_07    b29_LC8_07  \\\n",
       "count  ...  23177.000000  23177.000000  23177.000000  23177.000000   \n",
       "mean   ...   4054.567977    473.428356    410.961686    544.808215   \n",
       "std    ...   6661.986500   2223.950009    539.947680   2837.452024   \n",
       "min    ... -32768.000000 -32768.000000     -8.000000 -32768.000000   \n",
       "25%    ...   1413.000000    126.000000     88.000000    130.000000   \n",
       "50%    ...   2126.000000    246.000000    155.000000    271.000000   \n",
       "75%    ...   3500.000000    643.000000    588.000000    843.000000   \n",
       "max    ...  32767.000000  32767.000000   4128.000000  32767.000000   \n",
       "\n",
       "         b30_LC8_07    b31_LC8_07    b32_LC8_07    b33_LC8_07    b34_LC8_07  \\\n",
       "count  23177.000000  23177.000000  23177.000000  23177.000000  23177.000000   \n",
       "mean     685.495103    332.496527    303.484877    394.607499    499.365880   \n",
       "std      879.992656   1868.261448    395.559938   2580.861184    801.365571   \n",
       "min   -32000.000000 -32768.000000    -22.000000 -32768.000000 -31000.000000   \n",
       "25%      391.000000     87.000000     63.000000     94.000000    265.000000   \n",
       "50%      661.000000    173.000000    105.000000    189.000000    453.000000   \n",
       "75%      895.000000    458.000000    460.000000    620.000000    679.000000   \n",
       "max    32767.000000  32767.000000   2771.000000  32767.000000  32767.000000   \n",
       "\n",
       "         b35_LC8_07  \n",
       "count  23177.000000  \n",
       "mean     768.926047  \n",
       "std      455.468874  \n",
       "min    -9667.000000  \n",
       "25%      651.000000  \n",
       "50%      734.000000  \n",
       "75%      828.000000  \n",
       "max    32767.000000  \n",
       "\n",
       "[8 rows x 36 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_lake_depth_nd.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert the data in nparrays just for sklearn's sake\n",
    "(We won't do this in the RAPIDS env due to us having cuDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = overall_lake_depth_nd['Depth_m']\n",
    "covariate_spectral_bands = overall_lake_depth_nd.drop(['Depth_m'], axis=1)\n",
    "spectral_bands_list = list(covariate_spectral_bands.columns)\n",
    "#covariate_spectral_bands = np.array(covariate_spectral_bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates_train, covariates_test, labels_train, labels_test = train_test_split(covariate_spectral_bands,\n",
    "                                                                               labels, test_size = 0.2,\n",
    "                                                                               random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print('Training features shapes:', covariates_train.shape)\n",
    "print('Testing features shapes:', covariates_test.shape)\n",
    "print('Training labels shapes:', labels_train.shape)\n",
    "print('Testing labels shapes:', labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 7s, sys: 759 ms, total: 8min 7s\n",
      "Wall time: 8min 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=1000, random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf_model.fit(covariates_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.41 meters.\n",
      "CPU times: user 1.49 s, sys: 194 ms, total: 1.68 s\n",
      "Wall time: 1.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = rf_model.predict(covariates_test)\n",
    "errors = abs(predictions - labels_test)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'meters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate mean absolute percentage error (MAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.59 %.\n"
     ]
    }
   ],
   "source": [
    "mape = 100 * (errors / labels_test)\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy,2),'%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on bands 1-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b1_LC8_075', 'b2_LC8_075', 'b3_LC8_075', 'b4_LC8_075', 'b5_LC8_075', 'b6_LC8_075']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1_LC8_075</th>\n",
       "      <th>b2_LC8_075</th>\n",
       "      <th>b3_LC8_075</th>\n",
       "      <th>b4_LC8_075</th>\n",
       "      <th>b5_LC8_075</th>\n",
       "      <th>b6_LC8_075</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8678</th>\n",
       "      <td>236</td>\n",
       "      <td>428</td>\n",
       "      <td>488</td>\n",
       "      <td>1665</td>\n",
       "      <td>1523</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12893</th>\n",
       "      <td>83</td>\n",
       "      <td>190</td>\n",
       "      <td>82</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22839</th>\n",
       "      <td>-9</td>\n",
       "      <td>179</td>\n",
       "      <td>100</td>\n",
       "      <td>349</td>\n",
       "      <td>235</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4877</th>\n",
       "      <td>161</td>\n",
       "      <td>251</td>\n",
       "      <td>74</td>\n",
       "      <td>47</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19022</th>\n",
       "      <td>212</td>\n",
       "      <td>297</td>\n",
       "      <td>205</td>\n",
       "      <td>71</td>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       b1_LC8_075  b2_LC8_075  b3_LC8_075  b4_LC8_075  b5_LC8_075  b6_LC8_075\n",
       "8678          236         428         488        1665        1523         869\n",
       "12893          83         190          82          29          30          25\n",
       "22839          -9         179         100         349         235         190\n",
       "4877          161         251          74          47          31          19\n",
       "19022         212         297         205          71          35          23"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_cols_idx = covariate_spectral_bands.columns[:6]\n",
    "covariate_spectral_bands_adjusted = covariate_spectral_bands[adjusted_cols_idx]\n",
    "cv_one_six_train, cv_one_six_test, l_one_six_train, l_one_six_test = train_test_split(covariate_spectral_bands_adjusted,\n",
    "                                                                                      labels, \n",
    "                                                                                      test_size = 0.2,\n",
    "                                                                                      shuffle=True,\n",
    "                                                                                      random_state = 42)\n",
    "spectral_bands_list = list(covariate_spectral_bands_adjusted.columns)\n",
    "print(spectral_bands_list)\n",
    "cv_one_six_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 12s, sys: 601 ms, total: 1min 12s\n",
      "Wall time: 1min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=1000, random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf_one_six_model = RandomForestRegressor(n_estimators=1000, random_state=42)\n",
    "rf_one_six_model.fit(cv_one_six_train, l_one_six_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.42820041916003015\n",
      "r^2:  0.7777936578812373\n"
     ]
    }
   ],
   "source": [
    "preds_one_six = rf_one_six_model.predict(cv_one_six_test)\n",
    "mae_score = mean_absolute_error(l_one_six_test, preds_one_six)\n",
    "r2 = r2_score(l_one_six_test, preds_one_six)\n",
    "print(\"MAE: \", mae_score)\n",
    "print(\"r^2: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(rf_one_six_model, \n",
    "                                cv_one_six_train, \n",
    "                                l_one_six_train, \n",
    "                                n_repeats=5, \n",
    "                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables: b3_LC8_075           Importance: 1.92171\n",
      "Variables: b1_LC8_075           Importance: 1.68431\n",
      "Variables: b4_LC8_075           Importance: 1.04489\n",
      "Variables: b2_LC8_075           Importance: 0.48516\n",
      "Variables: b5_LC8_075           Importance: 0.45505\n",
      "Variables: b6_LC8_075           Importance: 0.17904\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importances_mean:  [1.68430603 0.48516472 1.92170922 1.04488831 0.45504982 0.17903567]\n",
      "Importances_std:  [0.01990674 0.01168463 0.02990808 0.01656078 0.0056657  0.00213915]\n"
     ]
    }
   ],
   "source": [
    "cv_list = list(cv_one_six_train.columns)\n",
    "importance = result.importances_mean\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "sorted_idx = np.flip(sorted_idx)\n",
    "feature_importances = [(feature, (round(importance, 5))) for feature, importance in zip(cv_list, importance)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Variables: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.bar([x for x in range(len(importance))], importance[sorted_idx])\n",
    "\n",
    "x_tick_list = cv_one_six_train.columns[sorted_idx]\n",
    "x_tick_adjusted_length = []\n",
    "for tick in x_tick_list:\n",
    "    x_tick_adjusted_length.append(tick[:3])\n",
    "\n",
    "plt.xticks(range(len(importance)), x_tick_adjusted_length)\n",
    "plt.title(\"Mean Permutation_importance n_iters=5\")\n",
    "plt.show()\n",
    "print(\"Importances_mean: \",result.importances_mean)\n",
    "print(\"Importances_std: \",result.importances_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize a single decision tree\n",
    "I think this is a really cool visual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain model for smaller graph\n",
    "rf_small = RandomForestRegressor(n_estimators=10, max_depth=3)\n",
    "rf_small.fit(covariates_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical importances\n",
    "importances = list(rf_model.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 2)) for\n",
    "                      feature, importance in zip(spectral_bands_list, importances)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables: b8_LC8_075           Importance: 0.14\n",
      "Variables: b17_LC8_07           Importance: 0.08\n",
      "Variables: b24_LC8_07           Importance: 0.08\n",
      "Variables: b18_LC8_07           Importance: 0.07\n",
      "Variables: b7_LC8_075           Importance: 0.06\n",
      "Variables: b13_LC8_07           Importance: 0.05\n",
      "Variables: b1_LC8_075           Importance: 0.04\n",
      "Variables: b2_LC8_075           Importance: 0.03\n",
      "Variables: b12_LC8_07           Importance: 0.03\n",
      "Variables: b14_LC8_07           Importance: 0.03\n",
      "Variables: b19_LC8_07           Importance: 0.03\n",
      "Variables: b22_LC8_07           Importance: 0.03\n",
      "Variables: b25_LC8_07           Importance: 0.03\n",
      "Variables: b3_LC8_075           Importance: 0.02\n",
      "Variables: b4_LC8_075           Importance: 0.02\n",
      "Variables: b5_LC8_075           Importance: 0.02\n",
      "Variables: b6_LC8_075           Importance: 0.02\n",
      "Variables: b9_LC8_075           Importance: 0.02\n",
      "Variables: b23_LC8_07           Importance: 0.02\n",
      "Variables: b26_LC8_07           Importance: 0.02\n",
      "Variables: b30_LC8_07           Importance: 0.02\n",
      "Variables: b31_LC8_07           Importance: 0.02\n",
      "Variables: b34_LC8_07           Importance: 0.02\n",
      "Variables: b35_LC8_07           Importance: 0.02\n",
      "Variables: b10_LC8_07           Importance: 0.01\n",
      "Variables: b11_LC8_07           Importance: 0.01\n",
      "Variables: b15_LC8_07           Importance: 0.01\n",
      "Variables: b16_LC8_07           Importance: 0.01\n",
      "Variables: b20_LC8_07           Importance: 0.01\n",
      "Variables: b21_LC8_07           Importance: 0.01\n",
      "Variables: b27_LC8_07           Importance: 0.01\n",
      "Variables: b28_LC8_07           Importance: 0.01\n",
      "Variables: b29_LC8_07           Importance: 0.01\n",
      "Variables: b32_LC8_07           Importance: 0.01\n",
      "Variables: b33_LC8_07           Importance: 0.01\n"
     ]
    }
   ],
   "source": [
    "[print('Variables: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a new random forest w/ Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_most_important = RandomForestRegressor(n_estimators = 1000, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18541, 6)\n",
      "(4636, 6)\n"
     ]
    }
   ],
   "source": [
    "important_indeces = [spectral_bands_list.index('b8_LC8_075'), spectral_bands_list.index('b17_LC8_07'),\n",
    "                    spectral_bands_list.index('b24_LC8_07'), spectral_bands_list.index('b18_LC8_07'),\n",
    "                    spectral_bands_list.index('b7_LC8_075'), spectral_bands_list.index('b13_LC8_07')]\n",
    "train_important = covariates_train[:, important_indeces]\n",
    "test_important = covariates_test[:, important_indeces]\n",
    "print(train_important.shape)\n",
    "print(test_important.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 26s, sys: 714 ms, total: 1min 27s\n",
      "Wall time: 1min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=1000, random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf_most_important.fit(train_important, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.53 metres.\n",
      "Accuracy: 72.19 %.\n"
     ]
    }
   ],
   "source": [
    "predictions = rf_most_important.predict(test_important)\n",
    "errors = abs(predictions - labels_test)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'metres.')\n",
    "mape = np.mean(100 * (errors / labels_test))\n",
    "accuracy = 100 - mape\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-rapids-0.16]",
   "language": "python",
   "name": "conda-env-.conda-rapids-0.16-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
