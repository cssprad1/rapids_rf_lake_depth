{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask and cuDF working together\n",
    "\n",
    "Converting some of the code to work with Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sytem and python modules\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "# Import RAPIDS specific modules\n",
    "\n",
    "import cudf as df\n",
    "import cuml\n",
    "from cuml import train_test_split\n",
    "from cuml.metrics.regression import r2_score as r2d2\n",
    "\n",
    "# Import Dask specific modules\n",
    "from cuml.dask.common import utils as dask_utils\n",
    "from dask.distributed import Client, wait\n",
    "from dask_cuda import LocalCUDACluster\n",
    "import dask_cudf\n",
    "\n",
    "from cuml.dask.ensemble import RandomForestRegressor as cumlDaskRF\n",
    "\n",
    "# Import sklearn specific modules\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Import data-visualization modules\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Dask Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cssprad1/.conda/envs/myRapids/lib/python3.7/site-packages/distributed/node.py:155: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 41157 instead\n",
      "  http_address[\"port\"], self.http_server.port\n"
     ]
    }
   ],
   "source": [
    "# This will use all GPUs on the local host by default\n",
    "cluster = LocalCUDACluster(threads_per_worker=1)\n",
    "c = Client(cluster)\n",
    "\n",
    "# Query the client for all connected workers\n",
    "workers = c.has_what().keys()\n",
    "n_workers = len(workers)\n",
    "n_streams = 8 # Performance optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare some globals variables and paths\n",
    "FEATURES_PATH = '../data/pts_merged_final.csv'\n",
    "DEPTH = 'Depth_m'\n",
    "DATE = 'Date'\n",
    "FID = 'FID'\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load everything into GPU-based DF\n",
    "lakes_depth_df = df.read_csv(FEATURES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depth_m</th>\n",
       "      <th>b1_LC8_075</th>\n",
       "      <th>b2_LC8_075</th>\n",
       "      <th>b3_LC8_075</th>\n",
       "      <th>b4_LC8_075</th>\n",
       "      <th>b5_LC8_075</th>\n",
       "      <th>b6_LC8_075</th>\n",
       "      <th>b7_LC8_075</th>\n",
       "      <th>b8_LC8_075</th>\n",
       "      <th>b9_LC8_075</th>\n",
       "      <th>...</th>\n",
       "      <th>b26_LC8_07</th>\n",
       "      <th>b27_LC8_07</th>\n",
       "      <th>b28_LC8_07</th>\n",
       "      <th>b29_LC8_07</th>\n",
       "      <th>b30_LC8_07</th>\n",
       "      <th>b31_LC8_07</th>\n",
       "      <th>b32_LC8_07</th>\n",
       "      <th>b33_LC8_07</th>\n",
       "      <th>b34_LC8_07</th>\n",
       "      <th>b35_LC8_07</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.630000</td>\n",
       "      <td>164</td>\n",
       "      <td>271</td>\n",
       "      <td>199</td>\n",
       "      <td>42</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>605</td>\n",
       "      <td>824</td>\n",
       "      <td>3905</td>\n",
       "      <td>...</td>\n",
       "      <td>2625</td>\n",
       "      <td>165</td>\n",
       "      <td>100</td>\n",
       "      <td>136</td>\n",
       "      <td>643</td>\n",
       "      <td>98</td>\n",
       "      <td>59</td>\n",
       "      <td>80</td>\n",
       "      <td>381</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.672727</td>\n",
       "      <td>165</td>\n",
       "      <td>272</td>\n",
       "      <td>196</td>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>607</td>\n",
       "      <td>842</td>\n",
       "      <td>3750</td>\n",
       "      <td>...</td>\n",
       "      <td>2750</td>\n",
       "      <td>176</td>\n",
       "      <td>107</td>\n",
       "      <td>148</td>\n",
       "      <td>659</td>\n",
       "      <td>97</td>\n",
       "      <td>59</td>\n",
       "      <td>82</td>\n",
       "      <td>364</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.670588</td>\n",
       "      <td>154</td>\n",
       "      <td>260</td>\n",
       "      <td>193</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>592</td>\n",
       "      <td>798</td>\n",
       "      <td>3850</td>\n",
       "      <td>...</td>\n",
       "      <td>2105</td>\n",
       "      <td>208</td>\n",
       "      <td>123</td>\n",
       "      <td>166</td>\n",
       "      <td>800</td>\n",
       "      <td>123</td>\n",
       "      <td>73</td>\n",
       "      <td>98</td>\n",
       "      <td>475</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.822222</td>\n",
       "      <td>156</td>\n",
       "      <td>250</td>\n",
       "      <td>195</td>\n",
       "      <td>48</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "      <td>624</td>\n",
       "      <td>800</td>\n",
       "      <td>3250</td>\n",
       "      <td>...</td>\n",
       "      <td>1846</td>\n",
       "      <td>256</td>\n",
       "      <td>160</td>\n",
       "      <td>205</td>\n",
       "      <td>833</td>\n",
       "      <td>167</td>\n",
       "      <td>104</td>\n",
       "      <td>133</td>\n",
       "      <td>542</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.725000</td>\n",
       "      <td>117</td>\n",
       "      <td>164</td>\n",
       "      <td>78</td>\n",
       "      <td>38</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>713</td>\n",
       "      <td>1500</td>\n",
       "      <td>3079</td>\n",
       "      <td>...</td>\n",
       "      <td>2235</td>\n",
       "      <td>197</td>\n",
       "      <td>140</td>\n",
       "      <td>295</td>\n",
       "      <td>605</td>\n",
       "      <td>145</td>\n",
       "      <td>104</td>\n",
       "      <td>218</td>\n",
       "      <td>447</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Depth_m  b1_LC8_075  b2_LC8_075  b3_LC8_075  b4_LC8_075  b5_LC8_075  \\\n",
       "0  0.630000         164         271         199          42          27   \n",
       "1  0.672727         165         272         196          44          29   \n",
       "2  0.670588         154         260         193          40          32   \n",
       "3  0.822222         156         250         195          48          40   \n",
       "4  1.725000         117         164          78          38          23   \n",
       "\n",
       "   b6_LC8_075  b7_LC8_075  b8_LC8_075  b9_LC8_075  ...  b26_LC8_07  \\\n",
       "0          16         605         824        3905  ...        2625   \n",
       "1          16         607         842        3750  ...        2750   \n",
       "2          19         592         798        3850  ...        2105   \n",
       "3          26         624         800        3250  ...        1846   \n",
       "4          17         713        1500        3079  ...        2235   \n",
       "\n",
       "   b27_LC8_07  b28_LC8_07  b29_LC8_07  b30_LC8_07  b31_LC8_07  b32_LC8_07  \\\n",
       "0         165         100         136         643          98          59   \n",
       "1         176         107         148         659          97          59   \n",
       "2         208         123         166         800         123          73   \n",
       "3         256         160         205         833         167         104   \n",
       "4         197         140         295         605         145         104   \n",
       "\n",
       "   b33_LC8_07  b34_LC8_07  b35_LC8_07  \n",
       "0          80         381         593  \n",
       "1          82         364         552  \n",
       "2          98         475         594  \n",
       "3         133         542         650  \n",
       "4         218         447         739  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unnecessary values from DF\n",
    "lakes_depth_nd = lakes_depth_df.drop(['FID', 'Date'], axis = 1)\n",
    "lakes_depth_nd.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depth_m</th>\n",
       "      <th>b1_LC8_075</th>\n",
       "      <th>b2_LC8_075</th>\n",
       "      <th>b3_LC8_075</th>\n",
       "      <th>b4_LC8_075</th>\n",
       "      <th>b5_LC8_075</th>\n",
       "      <th>b6_LC8_075</th>\n",
       "      <th>b7_LC8_075</th>\n",
       "      <th>b8_LC8_075</th>\n",
       "      <th>b9_LC8_075</th>\n",
       "      <th>...</th>\n",
       "      <th>b26_LC8_07</th>\n",
       "      <th>b27_LC8_07</th>\n",
       "      <th>b28_LC8_07</th>\n",
       "      <th>b29_LC8_07</th>\n",
       "      <th>b30_LC8_07</th>\n",
       "      <th>b31_LC8_07</th>\n",
       "      <th>b32_LC8_07</th>\n",
       "      <th>b33_LC8_07</th>\n",
       "      <th>b34_LC8_07</th>\n",
       "      <th>b35_LC8_07</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "      <td>23177.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.221400</td>\n",
       "      <td>424.288001</td>\n",
       "      <td>553.758079</td>\n",
       "      <td>427.147301</td>\n",
       "      <td>312.433188</td>\n",
       "      <td>175.490055</td>\n",
       "      <td>132.437373</td>\n",
       "      <td>558.585451</td>\n",
       "      <td>922.828753</td>\n",
       "      <td>1900.034603</td>\n",
       "      <td>...</td>\n",
       "      <td>4054.567977</td>\n",
       "      <td>473.428356</td>\n",
       "      <td>410.961686</td>\n",
       "      <td>544.808215</td>\n",
       "      <td>685.495103</td>\n",
       "      <td>332.496527</td>\n",
       "      <td>303.484877</td>\n",
       "      <td>394.607499</td>\n",
       "      <td>499.365880</td>\n",
       "      <td>768.926047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.872953</td>\n",
       "      <td>755.932158</td>\n",
       "      <td>731.549284</td>\n",
       "      <td>630.296958</td>\n",
       "      <td>479.544589</td>\n",
       "      <td>309.819959</td>\n",
       "      <td>244.022402</td>\n",
       "      <td>402.546098</td>\n",
       "      <td>2850.095960</td>\n",
       "      <td>3253.968664</td>\n",
       "      <td>...</td>\n",
       "      <td>6661.986500</td>\n",
       "      <td>2223.950009</td>\n",
       "      <td>539.947680</td>\n",
       "      <td>2837.452024</td>\n",
       "      <td>879.992656</td>\n",
       "      <td>1868.261448</td>\n",
       "      <td>395.559938</td>\n",
       "      <td>2580.861184</td>\n",
       "      <td>801.365571</td>\n",
       "      <td>455.468874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>-151.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>-39.000000</td>\n",
       "      <td>-38.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-3213.000000</td>\n",
       "      <td>-32768.000000</td>\n",
       "      <td>-32768.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-32768.000000</td>\n",
       "      <td>-32768.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-32768.000000</td>\n",
       "      <td>-32000.000000</td>\n",
       "      <td>-32768.000000</td>\n",
       "      <td>-22.000000</td>\n",
       "      <td>-32768.000000</td>\n",
       "      <td>-31000.000000</td>\n",
       "      <td>-9667.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.405170</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>607.000000</td>\n",
       "      <td>753.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1413.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>391.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>651.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.870750</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>621.000000</td>\n",
       "      <td>933.000000</td>\n",
       "      <td>1626.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2126.000000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>271.000000</td>\n",
       "      <td>661.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>453.000000</td>\n",
       "      <td>734.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.348770</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>441.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>789.000000</td>\n",
       "      <td>1241.000000</td>\n",
       "      <td>3294.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3500.000000</td>\n",
       "      <td>643.000000</td>\n",
       "      <td>588.000000</td>\n",
       "      <td>843.000000</td>\n",
       "      <td>895.000000</td>\n",
       "      <td>458.000000</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>620.000000</td>\n",
       "      <td>679.000000</td>\n",
       "      <td>828.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.037500</td>\n",
       "      <td>5277.000000</td>\n",
       "      <td>5442.000000</td>\n",
       "      <td>4984.000000</td>\n",
       "      <td>5370.000000</td>\n",
       "      <td>2879.000000</td>\n",
       "      <td>2568.000000</td>\n",
       "      <td>4171.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>4128.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>2771.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "      <td>32767.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Depth_m    b1_LC8_075    b2_LC8_075    b3_LC8_075    b4_LC8_075  \\\n",
       "count  23177.000000  23177.000000  23177.000000  23177.000000  23177.000000   \n",
       "mean       2.221400    424.288001    553.758079    427.147301    312.433188   \n",
       "std        1.872953    755.932158    731.549284    630.296958    479.544589   \n",
       "min        0.250000   -151.000000     47.000000    -39.000000    -38.000000   \n",
       "25%        1.405170    128.000000    235.000000    116.000000     52.000000   \n",
       "50%        1.870750    189.000000    324.000000    224.000000    118.000000   \n",
       "75%        2.348770    262.000000    441.000000    379.000000    337.000000   \n",
       "max       21.037500   5277.000000   5442.000000   4984.000000   5370.000000   \n",
       "\n",
       "         b5_LC8_075    b6_LC8_075    b7_LC8_075    b8_LC8_075    b9_LC8_075  \\\n",
       "count  23177.000000  23177.000000  23177.000000  23177.000000  23177.000000   \n",
       "mean     175.490055    132.437373    558.585451    922.828753   1900.034603   \n",
       "std      309.819959    244.022402    402.546098   2850.095960   3253.968664   \n",
       "min       -3.000000     -9.000000  -3213.000000 -32768.000000 -32768.000000   \n",
       "25%       29.000000     20.000000    429.000000    607.000000    753.000000   \n",
       "50%       51.000000     37.000000    621.000000    933.000000   1626.000000   \n",
       "75%      164.000000    120.000000    789.000000   1241.000000   3294.000000   \n",
       "max     2879.000000   2568.000000   4171.000000  32767.000000  32767.000000   \n",
       "\n",
       "       ...    b26_LC8_07    b27_LC8_07    b28_LC8_07    b29_LC8_07  \\\n",
       "count  ...  23177.000000  23177.000000  23177.000000  23177.000000   \n",
       "mean   ...   4054.567977    473.428356    410.961686    544.808215   \n",
       "std    ...   6661.986500   2223.950009    539.947680   2837.452024   \n",
       "min    ... -32768.000000 -32768.000000     -8.000000 -32768.000000   \n",
       "25%    ...   1413.000000    126.000000     88.000000    130.000000   \n",
       "50%    ...   2126.000000    246.000000    155.000000    271.000000   \n",
       "75%    ...   3500.000000    643.000000    588.000000    843.000000   \n",
       "max    ...  32767.000000  32767.000000   4128.000000  32767.000000   \n",
       "\n",
       "         b30_LC8_07    b31_LC8_07    b32_LC8_07    b33_LC8_07    b34_LC8_07  \\\n",
       "count  23177.000000  23177.000000  23177.000000  23177.000000  23177.000000   \n",
       "mean     685.495103    332.496527    303.484877    394.607499    499.365880   \n",
       "std      879.992656   1868.261448    395.559938   2580.861184    801.365571   \n",
       "min   -32000.000000 -32768.000000    -22.000000 -32768.000000 -31000.000000   \n",
       "25%      391.000000     87.000000     63.000000     94.000000    265.000000   \n",
       "50%      661.000000    173.000000    105.000000    189.000000    453.000000   \n",
       "75%      895.000000    458.000000    460.000000    620.000000    679.000000   \n",
       "max    32767.000000  32767.000000   2771.000000  32767.000000  32767.000000   \n",
       "\n",
       "         b35_LC8_07  \n",
       "count  23177.000000  \n",
       "mean     768.926047  \n",
       "std      455.468874  \n",
       "min    -9667.000000  \n",
       "25%      651.000000  \n",
       "50%      734.000000  \n",
       "75%      828.000000  \n",
       "max    32767.000000  \n",
       "\n",
       "[8 rows x 36 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect data for any anomolies or anything else odd-looking\n",
    "lakes_depth_nd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.630000\n",
       "1    0.672727\n",
       "2    0.670588\n",
       "3    0.822222\n",
       "4    1.725000\n",
       "Name: Depth_m, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make our acutal_predictions i.e. labels and our covariates dataframes\n",
    "labels = lakes_depth_nd['Depth_m']\n",
    "covariates = lakes_depth_nd.drop(['Depth_m'], axis=1)\n",
    "\n",
    "# Check to ensure everything looks good\n",
    "labels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1_LC8_075</th>\n",
       "      <th>b2_LC8_075</th>\n",
       "      <th>b3_LC8_075</th>\n",
       "      <th>b4_LC8_075</th>\n",
       "      <th>b5_LC8_075</th>\n",
       "      <th>b6_LC8_075</th>\n",
       "      <th>b7_LC8_075</th>\n",
       "      <th>b8_LC8_075</th>\n",
       "      <th>b9_LC8_075</th>\n",
       "      <th>b10_LC8_07</th>\n",
       "      <th>...</th>\n",
       "      <th>b26_LC8_07</th>\n",
       "      <th>b27_LC8_07</th>\n",
       "      <th>b28_LC8_07</th>\n",
       "      <th>b29_LC8_07</th>\n",
       "      <th>b30_LC8_07</th>\n",
       "      <th>b31_LC8_07</th>\n",
       "      <th>b32_LC8_07</th>\n",
       "      <th>b33_LC8_07</th>\n",
       "      <th>b34_LC8_07</th>\n",
       "      <th>b35_LC8_07</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>164</td>\n",
       "      <td>271</td>\n",
       "      <td>199</td>\n",
       "      <td>42</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>605</td>\n",
       "      <td>824</td>\n",
       "      <td>3905</td>\n",
       "      <td>6074</td>\n",
       "      <td>...</td>\n",
       "      <td>2625</td>\n",
       "      <td>165</td>\n",
       "      <td>100</td>\n",
       "      <td>136</td>\n",
       "      <td>643</td>\n",
       "      <td>98</td>\n",
       "      <td>59</td>\n",
       "      <td>80</td>\n",
       "      <td>381</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165</td>\n",
       "      <td>272</td>\n",
       "      <td>196</td>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>607</td>\n",
       "      <td>842</td>\n",
       "      <td>3750</td>\n",
       "      <td>5690</td>\n",
       "      <td>...</td>\n",
       "      <td>2750</td>\n",
       "      <td>176</td>\n",
       "      <td>107</td>\n",
       "      <td>148</td>\n",
       "      <td>659</td>\n",
       "      <td>97</td>\n",
       "      <td>59</td>\n",
       "      <td>82</td>\n",
       "      <td>364</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>154</td>\n",
       "      <td>260</td>\n",
       "      <td>193</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>592</td>\n",
       "      <td>798</td>\n",
       "      <td>3850</td>\n",
       "      <td>4813</td>\n",
       "      <td>...</td>\n",
       "      <td>2105</td>\n",
       "      <td>208</td>\n",
       "      <td>123</td>\n",
       "      <td>166</td>\n",
       "      <td>800</td>\n",
       "      <td>123</td>\n",
       "      <td>73</td>\n",
       "      <td>98</td>\n",
       "      <td>475</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156</td>\n",
       "      <td>250</td>\n",
       "      <td>195</td>\n",
       "      <td>48</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "      <td>624</td>\n",
       "      <td>800</td>\n",
       "      <td>3250</td>\n",
       "      <td>3900</td>\n",
       "      <td>...</td>\n",
       "      <td>1846</td>\n",
       "      <td>256</td>\n",
       "      <td>160</td>\n",
       "      <td>205</td>\n",
       "      <td>833</td>\n",
       "      <td>167</td>\n",
       "      <td>104</td>\n",
       "      <td>133</td>\n",
       "      <td>542</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117</td>\n",
       "      <td>164</td>\n",
       "      <td>78</td>\n",
       "      <td>38</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>713</td>\n",
       "      <td>1500</td>\n",
       "      <td>3079</td>\n",
       "      <td>5087</td>\n",
       "      <td>...</td>\n",
       "      <td>2235</td>\n",
       "      <td>197</td>\n",
       "      <td>140</td>\n",
       "      <td>295</td>\n",
       "      <td>605</td>\n",
       "      <td>145</td>\n",
       "      <td>104</td>\n",
       "      <td>218</td>\n",
       "      <td>447</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   b1_LC8_075  b2_LC8_075  b3_LC8_075  b4_LC8_075  b5_LC8_075  b6_LC8_075  \\\n",
       "0         164         271         199          42          27          16   \n",
       "1         165         272         196          44          29          16   \n",
       "2         154         260         193          40          32          19   \n",
       "3         156         250         195          48          40          26   \n",
       "4         117         164          78          38          23          17   \n",
       "\n",
       "   b7_LC8_075  b8_LC8_075  b9_LC8_075  b10_LC8_07  ...  b26_LC8_07  \\\n",
       "0         605         824        3905        6074  ...        2625   \n",
       "1         607         842        3750        5690  ...        2750   \n",
       "2         592         798        3850        4813  ...        2105   \n",
       "3         624         800        3250        3900  ...        1846   \n",
       "4         713        1500        3079        5087  ...        2235   \n",
       "\n",
       "   b27_LC8_07  b28_LC8_07  b29_LC8_07  b30_LC8_07  b31_LC8_07  b32_LC8_07  \\\n",
       "0         165         100         136         643          98          59   \n",
       "1         176         107         148         659          97          59   \n",
       "2         208         123         166         800         123          73   \n",
       "3         256         160         205         833         167         104   \n",
       "4         197         140         295         605         145         104   \n",
       "\n",
       "   b33_LC8_07  b34_LC8_07  b35_LC8_07  \n",
       "0          80         381         593  \n",
       "1          82         364         552  \n",
       "2          98         475         594  \n",
       "3         133         542         650  \n",
       "4         218         447         739  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariates.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we change all our covariate and label data to float32\n",
    "\n",
    "labels = labels.astype(cp.float32)\n",
    "covariates = covariates.astype(cp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_train, cv_test, labels_train, labels_test = train_test_split(covariates, labels,\n",
    "                                                               test_size=TEST_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (18542, 35)\n",
      "Testing features shape: (4635, 35)\n",
      "Training labels shape: (18542,)\n",
      "Testing labels shape: (4635,)\n"
     ]
    }
   ],
   "source": [
    "# Ensure we have the right size and shapes on our split data\n",
    "print('Training features shape:', cv_train.shape)\n",
    "print('Testing features shape:', cv_test.shape)\n",
    "print('Training labels shape:', labels_train.shape)\n",
    "print('Testing labels shape:', labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribute data to worker GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_partitions = n_workers\n",
    "\n",
    "def distribute(covariates, labels):\n",
    "\n",
    "    # Partition with Dask\n",
    "    # In this case, each worker will train on 1/n_partitions fraction of the data\n",
    "    cv_dask = dask_cudf.from_cudf(covariates, npartitions=n_partitions)\n",
    "    labels_dask = dask_cudf.from_cudf(labels, npartitions=n_partitions)\n",
    "\n",
    "    # Persist to cache the data in active memory\n",
    "    cv_dask, labels_dask = \\\n",
    "      dask_utils.persist_across_workers(c, [cv_dask, labels_dask], workers=workers)\n",
    "    \n",
    "    return cv_dask, labels_dask\n",
    "\n",
    "cv_train_dask, labels_train_dask = distribute(cv_train, labels_train)\n",
    "cv_test_dask, labels_test_dask = distribute(cv_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the distributed cuML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare some global variables for training phase\n",
    "\n",
    "# Hyper-paramters\n",
    "N_ESTIMATORS = 1000\n",
    "SPLIT_ALGO = 1\n",
    "SPLIT_CRITERION = 2\n",
    "BOOTSTRAP = True\n",
    "BOOTSTRAP_FEATURES = False\n",
    "ROWS_SAMPLE = 1.0\n",
    "MAX_DEPTH = 16\n",
    "MAX_LEAVES = -1\n",
    "MAX_FEATURES = 'auto'\n",
    "N_BINS = 8\n",
    "MIN_ROWS_PER_NODE = 2\n",
    "MIN_IMPURITY_DECREASE = 0.0\n",
    "ACCURACY_METRIC = 'mean_ae' # 'mse' #'r2' # 'median_aw' # \n",
    "QUANTILEPT = False\n",
    "SEED = 42\n",
    "VERBOSE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_rf_model_0 = cumlDaskRF(n_estimators = N_ESTIMATORS, \n",
    "                        split_algo = SPLIT_ALGO, \n",
    "                        split_criterion = SPLIT_CRITERION, \n",
    "                        bootstrap = BOOTSTRAP,\n",
    "                        bootstrap_features = BOOTSTRAP_FEATURES, \n",
    "                        rows_sample = ROWS_SAMPLE,\n",
    "                        max_depth = MAX_DEPTH, \n",
    "                        max_leaves = MAX_LEAVES, \n",
    "                        max_features = MAX_FEATURES,\n",
    "                        n_bins = N_BINS,\n",
    "                        min_rows_per_node = MIN_ROWS_PER_NODE,\n",
    "                        min_impurity_decrease = MIN_IMPURITY_DECREASE,\n",
    "                        accuracy_metric = ACCURACY_METRIC,\n",
    "                        quantile_per_tree = QUANTILEPT,\n",
    "                        seed = SEED,\n",
    "                        verbose = VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 145 ms, sys: 32.6 ms, total: 178 ms\n",
      "Wall time: 4.07 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DoneAndNotDoneFutures(done={<Future: finished, type: cuml.RandomForestRegressor, key: _construct_rf-63fbe5e5-4ad9-4f01-adee-8bff43462bcc>}, not_done=set())"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "depth_rf_model_0.fit(cv_train_dask, labels_train_dask)\n",
    "wait(depth_rf_model_0.rfs) # Allow asynchronous training tasks to finish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuml_y_pred = depth_rf_model_0.predict(cv_test_dask).compute().to_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores --\n",
      "MAE:  1.0630636\n",
      "r2:  -0.04085518364929608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    }
   ],
   "source": [
    "# Let's get some prediction\n",
    "from sklearn.metrics import mean_absolute_error as m_a_e, r2_score as r2d2\n",
    "\n",
    "mae_score = m_a_e(labels_test.to_array(), cuml_y_pred)\n",
    "r2_score = r2d2(labels_test.to_array(), cuml_y_pred)\n",
    "print(\"Scores --\")\n",
    "print(\"MAE: \", mae_score)\n",
    "print(\"r2: \", r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-myRapids]",
   "language": "python",
   "name": "conda-env-.conda-myRapids-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
